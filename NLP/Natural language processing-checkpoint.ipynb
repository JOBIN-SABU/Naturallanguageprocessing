{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d11707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\85job\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "C:\\Users\\85job\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - accuracy: 0.6223 - loss: 5.6568\n",
      "Epoch 2/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.6542 - loss: 2.6859\n",
      "Epoch 3/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.6556 - loss: 2.5517\n",
      "Epoch 4/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.6596 - loss: 2.4255\n",
      "Epoch 5/5\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.6580 - loss: 2.3837\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Load the training data from a CSV file\n",
    "data = pd.read_csv(r\"C:\\Users\\85job\\Downloads\\Conversation.csv\") \n",
    "input_texts = data['question'].tolist()\n",
    "response_texts = data['answer'].tolist()\n",
    "\n",
    "# Tokenize the input and response texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_texts + response_texts)\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "response_sequences = tokenizer.texts_to_sequences(response_texts)\n",
    "\n",
    "# Pad the sequences\n",
    "max_sequence_length = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in response_sequences))\n",
    "input_sequences_padded = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "response_sequences_padded = pad_sequences(response_sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Convert responses to one-hot encoding\n",
    "response_sequences_one_hot = np.zeros((len(response_sequences_padded), max_sequence_length, len(tokenizer.word_index) + 1))\n",
    "for i, seq in enumerate(response_sequences_padded):\n",
    "    for j, word_index in enumerate(seq):\n",
    "        response_sequences_one_hot[i, j, word_index] = 1\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_sequences_padded, response_sequences_one_hot, epochs=5, batch_size=32)\n",
    "\n",
    "# Save the tokenizer and model\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "model.save('chatbot_model.keras')  # Save the model in the native Keras format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58eebe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.6632 - loss: 2.2890\n",
      "Accuracy: 66.01%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(input_sequences_padded, response_sequences_one_hot)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6e657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1f3e660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42613686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0ab17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
